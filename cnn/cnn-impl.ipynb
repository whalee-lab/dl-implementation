{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import packages & dependencies",
   "id": "80a911fb0f38ea30"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:31.385841Z",
     "start_time": "2025-12-16T05:58:30.984318Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Input image\n",
    "Here, say we assume a single grayscale image of size 8x8.\n",
    "Input image size (h): 8x8x1"
   ],
   "id": "7740c4cbeeab46ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:36.711898Z",
     "start_time": "2025-12-16T05:58:36.709333Z"
    }
   },
   "cell_type": "code",
   "source": "X = np.random.randn(8,8)",
   "id": "d6fdca1bf1556c31",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Convolution layer",
   "id": "9ad4a81a34a5ba3e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:38.086495Z",
     "start_time": "2025-12-16T05:58:38.081913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define filters here, of dim 3x3x2\n",
    "num_filters = 2\n",
    "filter_size = 3\n",
    "\n",
    "filters = np.random.randn(num_filters, filter_size, filter_size)\n",
    "bias = np.zeros(num_filters)\n",
    "\n",
    "# convolution operation\n",
    "def convolve(X, filters, bias):\n",
    "    h, w = X.shape\n",
    "    num_filters, f, _ = filters.shape\n",
    "\n",
    "    output_dim = h - f + 1\n",
    "    out = np.zeros((num_filters, output_dim, output_dim))\n",
    "\n",
    "    for k in range(num_filters):\n",
    "        for i in range(output_dim):\n",
    "            for j in range(output_dim):\n",
    "                region = X[i:i+f, j:j+f]\n",
    "                out[k, i, j] = np.sum(region * filters[k]) + bias[k]\n",
    "\n",
    "    return out\n",
    "\n",
    "conv_out = convolve(X, filters, bias)"
   ],
   "id": "d654b70f0c9694f2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Relu Activation",
   "id": "d1a9b81a15f1e864"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:41.101024Z",
     "start_time": "2025-12-16T05:58:41.098621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def relu(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "relu_out = relu(conv_out)\n"
   ],
   "id": "85514539f7722194",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Max pooling",
   "id": "63024abc883123af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:43.321472Z",
     "start_time": "2025-12-16T05:58:43.318060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def max_pool(X, size=2, stride=2):\n",
    "    num_filters, h, w = X.shape\n",
    "    out_dim = h // stride\n",
    "    out = np.zeros((num_filters, out_dim, out_dim))\n",
    "\n",
    "    for k in range(num_filters):\n",
    "        for i in range(0, h, stride):\n",
    "            for j in range(0, w, stride):\n",
    "                region = X[k, i:i+size, j:j+size]\n",
    "                out[k, i//stride, j//stride] = np.max(region)\n",
    "\n",
    "    return out\n",
    "\n",
    "pool_out = max_pool(relu_out)"
   ],
   "id": "5158c6f8c56ba0d9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Flatten",
   "id": "b916873182031552"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:58:46.032913Z",
     "start_time": "2025-12-16T05:58:46.030537Z"
    }
   },
   "cell_type": "code",
   "source": "flattened = pool_out.reshape(-1)\n",
   "id": "d142ed9cfd7149b0",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fully Connected Layer",
   "id": "e808601f5ca7706f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T05:59:14.891502Z",
     "start_time": "2025-12-16T05:59:14.888613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# initialize weights\n",
    "num_classes = 2\n",
    "\n",
    "W_fc = np.random.randn(18, num_classes)\n",
    "b_fc = np.zeros(num_classes)\n",
    "\n",
    "# Forward pass\n",
    "logits = flattened @ W_fc + b_fc"
   ],
   "id": "5aa74dcc53ac393e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Softmax probabilities",
   "id": "d0b3ebbe6576bfe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T06:01:00.051815Z",
     "start_time": "2025-12-16T06:01:00.049081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def softmax(z):\n",
    "    exp = np.exp(z - np.max(z))\n",
    "    return exp / np.sum(exp)\n",
    "\n",
    "probs = softmax(logits)"
   ],
   "id": "226ffe21d00a579e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prediction",
   "id": "e9ae0f830d1c23bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T06:01:14.869947Z",
     "start_time": "2025-12-16T06:01:14.867207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prediction = np.argmax(probs)\n",
    "print(prediction)"
   ],
   "id": "538edcc1421f9201",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loss function (Cross-Entropy)",
   "id": "46b635b810556f90"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T06:01:20.982843Z",
     "start_time": "2025-12-16T06:01:20.980371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_true = 1\n",
    "loss = -np.log(probs[y_true])\n"
   ],
   "id": "14bf20b319cbc917",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backprop through Fully Connected Layer",
   "id": "ffbca7ea3f96db05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:42.076718Z",
     "start_time": "2025-12-16T18:20:42.058022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dlogits = probs.copy()\n",
    "dlogits[y_true] -= 1\n",
    "\n",
    "# gradient wrt weights\n",
    "dW_fc = np.outer(flattened, dlogits)\n",
    "\n",
    "# gradient wrt bias\n",
    "db_fc = dlogits\n",
    "\n",
    "# gradient wrt input\n",
    "dflattened = W_fc @ dlogits\n"
   ],
   "id": "ab5abf27d144a17e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backprop through Flatten",
   "id": "feb09d07f35c9a65"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:44.327993Z",
     "start_time": "2025-12-16T18:20:44.325596Z"
    }
   },
   "cell_type": "code",
   "source": "dpool = dflattened.reshape(pool_out.shape)",
   "id": "687ad79fc3c2e79",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backprop through Max Pooling",
   "id": "bf9d1126b6757511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:46.327699Z",
     "start_time": "2025-12-16T18:20:46.319498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def max_pool_backward(dout, X, size=2, stride=2):\n",
    "    num_filters, h, w = X.shape\n",
    "    dX = np.zeros_like(X)\n",
    "\n",
    "    for k in range(num_filters):\n",
    "        for i in range(0, h, stride):\n",
    "            for j in range(0, w, stride):\n",
    "                region = X[k, i:i+size, j:j+size]\n",
    "                max_val = np.max(region)\n",
    "\n",
    "                for m in range(size):\n",
    "                    for n in range(size):\n",
    "                        if region[m, n] == max_val:\n",
    "                            dX[k, i+m, j+n] = dout[k, i//stride, j//stride]\n",
    "    return dX\n",
    "\n",
    "drelu = max_pool_backward(dpool, relu_out)"
   ],
   "id": "b60d591eca6c254",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backprop through ReLU",
   "id": "8825a9c988c0703b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:49.037924Z",
     "start_time": "2025-12-16T18:20:49.034963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dconv = drelu.copy()\n",
    "dconv[conv_out <= 0] = 0\n"
   ],
   "id": "ad0a6feb0e15ff45",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Backprop through Convolution (core part)",
   "id": "3294c94c36e31542"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:50.890301Z",
     "start_time": "2025-12-16T18:20:50.884989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dfilters = np.zeros_like(filters)\n",
    "dbias = np.zeros_like(bias)\n",
    "\n",
    "for k in range(num_filters):\n",
    "    dbias[k] = np.sum(dconv[k])\n",
    "\n",
    "    for i in range(dconv.shape[1]):\n",
    "        for j in range(dconv.shape[2]):\n",
    "            region = X[i:i+filter_size, j:j+filter_size]\n",
    "            dfilters[k] += dconv[k, i, j] * region\n",
    "\n",
    "# Gradient w.r.t input\n",
    "dX = np.zeros_like(X)\n",
    "\n",
    "for k in range(num_filters):\n",
    "    for i in range(dconv.shape[1]):\n",
    "        for j in range(dconv.shape[2]):\n",
    "            dX[i:i+filter_size, j:j+filter_size] += dconv[k, i, j] * filters[k]\n"
   ],
   "id": "3463b78e5ab7c891",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Weight update (Gradient Descent)",
   "id": "a89027509c779977"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:20:53.261787Z",
     "start_time": "2025-12-16T18:20:53.259432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lr = 0.01\n",
    "\n",
    "# update convolution layers\n",
    "filters -= lr * dfilters\n",
    "bias -= lr * dbias\n",
    "\n",
    "# update FC layer\n",
    "W_fc -= lr * dW_fc\n",
    "b_fc -= lr * db_fc\n"
   ],
   "id": "616c3e524b09e87e",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Output",
   "id": "b81287e961828c18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-16T18:23:42.440378Z",
     "start_time": "2025-12-16T18:23:42.431700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Probabilities:\", probs)\n",
    "print(\"Predicted class:\", prediction)\n",
    "print(\"Loss:\", loss)"
   ],
   "id": "acf5392a5cceed1e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.0072023 0.9927977]\n",
      "Predicted class: 1\n",
      "Loss: 0.007228358532233878\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
